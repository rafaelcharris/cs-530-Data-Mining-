{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJYE4F-jzHiD"
      },
      "source": [
        "# <center>Week 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3xNQTaGNzDxX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.compose import make_column_selector\n",
        "from sklearn import cluster\n",
        "# Models\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "# Model evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gCRcDwLIzXTN"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-uelMoaB5zj5"
      },
      "outputs": [],
      "source": [
        "X_train , X_test,y_train, y_test = train_test_split(df.drop(['label'], axis = 1), \n",
        "                                                    df['label'],\n",
        "                                                     test_size=0.33, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8uLK8dUQuH7"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "To increase speed and accuracy of the algorithm I scale the columns using StandardScaler on all the columns. What this function does is centering all the variables around the mean and divides them by the sd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qt5uyoHyQwyq"
      },
      "outputs": [],
      "source": [
        "col_trans = make_column_transformer(\n",
        "                                    (StandardScaler(),make_column_selector(dtype_include=np.number)),\n",
        "                                  remainder = 'passthrough')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIAiibI66Lqa"
      },
      "source": [
        "# Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et5BcN2-6VKz"
      },
      "source": [
        "## 1. Random Forest\n",
        "\n",
        "First, I call the random forest classifier, and create a pipeline so that it does all  preprocessing needed: scaling and feature aggregation, and then it run the random forest. To determine the number of clusters to use, i.e., the number of columns that I want the FeatureAggregation algorithm to return, I discussed with Ben that it is reasonable to use 196, which is like aggregating 4 pixels into 1. This can increase the effiency of the algorithms with the negative consequence of reducing the amount of information we have.\n",
        "To find the optimal number, it would be better include this parameter in the GridSearch, but it takes too long.\n",
        "I only added this parameter in the KNN gridsearch and found that 196 was the best among the options provided.\n",
        "I use gridsearch to find the max depth, the max number of features at each node, and the number of estimators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "feRLfJ-b6RhZ"
      },
      "outputs": [],
      "source": [
        "clf_rf = RandomForestClassifier() \n",
        "\n",
        "clf_rf_pipeline = Pipeline(steps = [\n",
        "    ('preprocess', col_trans),\n",
        "    ('feat_agg', cluster.FeatureAgglomeration(n_clusters=196)),\n",
        "    ('model', clf_rf)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tWIrlofTWPWj"
      },
      "outputs": [],
      "source": [
        "params_rf = {'model__max_depth' : [i + 1 for i in range(9, 12)],\n",
        "             'model__max_features': ['sqrt'],\n",
        "             'model__n_estimators': [i  for i in range(800, 1300, 100)]},\n",
        "\n",
        "clf_rf_gs = GridSearchCV(clf_rf_pipeline, cv = 5, param_grid=params_rf, \n",
        "                         scoring = 'accuracy', verbose = 10, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-3D7wdWr8Tv-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('preprocess',\n",
              "                                        ColumnTransformer(remainder='passthrough',\n",
              "                                                          transformers=[('standardscaler',\n",
              "                                                                         StandardScaler(),\n",
              "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x1371507c0>)])),\n",
              "                                       ('feat_agg',\n",
              "                                        FeatureAgglomeration(n_clusters=196)),\n",
              "                                       ('model', RandomForestClassifier())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=({'model__max_depth': [10, 11, 12],\n",
              "                          'model__max_features': ['sqrt'],\n",
              "                          'model__n_estimators': [800, 900, 1000, 1100,\n",
              "                                                  1200]},),\n",
              "             scoring='accuracy', verbose=10)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_rf_gs.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CfE2QGtf9ngK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__max_depth': 12,\n",
              " 'model__max_features': 'sqrt',\n",
              " 'model__n_estimators': 1200}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_rf_gs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oFolAR0w8gPO"
      },
      "outputs": [],
      "source": [
        "rf_preds = clf_rf_gs.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Iahw3Pe4-CRy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy score: 0.9506\n"
          ]
        }
      ],
      "source": [
        "print(f'accuracy score: {round(accuracy_score(y_test, rf_preds), 4)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE2DojHwFUrK"
      },
      "source": [
        "## 2. Multinomial Logistic Regression\n",
        "\n",
        "An alternative to the tree is a multinomial logistic regression. I use the l1 penalty term to reduce overfitting and I tune it using gridsearch.\n",
        "I have to change the solver to deal with multiple values in the `y_test` vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qYxSTTsQFZ2W"
      },
      "outputs": [],
      "source": [
        "clf_log = LogisticRegression(penalty = 'l1', solver = 'saga',\n",
        "                             max_iter= 1000)\n",
        "clf_log_pipeline = Pipeline(steps = [\n",
        "    ('preprocess', col_trans),\n",
        "    ('feat_agg', cluster.FeatureAgglomeration(n_clusters=196)),\n",
        "    ('model', clf_log)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bLxawyNs7wIU"
      },
      "outputs": [],
      "source": [
        "params_log = {'model__C' : list(np.linspace(0.01, 1, 10))}\n",
        "\n",
        "clf_log_gs = GridSearchCV(clf_log_pipeline, cv = 5, \n",
        "                          param_grid= params_log, \n",
        "                         scoring = 'accuracy', verbose = 10, error_score='raise',\n",
        "                         n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5GeMc9m7xBr"
      },
      "outputs": [],
      "source": [
        "clf_log_gs.fit(X_train, y_train)\n",
        "log_preds = clf_log_gs.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__C': 0.45}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_log_gs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "K3IYHvwVB2bP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The accuracy of the logistic regression was: 0.9183\n"
          ]
        }
      ],
      "source": [
        "print(f' The accuracy of the logistic regression was: {round(accuracy_score(y_test, log_preds), 4)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAHjcneAFtec"
      },
      "source": [
        "## 3. Neural Networks\n",
        "\n",
        "I run two NN, one without any tunning, and one in which I tune the learning rate and the number of layers in each hidden layer. \n",
        "This was interesting because the NN without any tunning overperformed the Random Forest and the Logistic Regressions and it was much faster than both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iqPG2U0HFylu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocess',\n",
              "                 ColumnTransformer(remainder='passthrough',\n",
              "                                   transformers=[('standardscaler',\n",
              "                                                  StandardScaler(),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x1371507c0>)])),\n",
              "                ('feat_agg', FeatureAgglomeration(n_clusters=196)),\n",
              "                ('model', MLPClassifier(max_iter=300, random_state=1))])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_nn = MLPClassifier(random_state=1, max_iter=300)\n",
        "\n",
        "nn_pipeline = Pipeline(steps=[\n",
        "                              ('preprocess', col_trans),\n",
        "    ('feat_agg', cluster.FeatureAgglomeration(n_clusters=196)),\n",
        "                              ('model', clf_nn)\n",
        "])\n",
        "\n",
        "\n",
        "nn_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "cRtyE3ffGtJS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The neural network's accuracy without any tuning is: 0.9674\n"
          ]
        }
      ],
      "source": [
        "nn_preds = nn_pipeline.predict(X_test)\n",
        "print(f\"The neural network's accuracy without any tuning is: {round(accuracy_score(y_test, nn_preds), 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The NN took only 27 seconds to run and achieve better accuracy than the logistic and the random forest. Both of which required tuning and more than 20 minutes to fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tuning Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_nn = {'model__alpha':list(np.linspace(0.001, .01, 8)),\n",
        "'model__hidden_layer_sizes': [(300, 300, ), (400, 400, )]\n",
        "}\n",
        "\n",
        "nn_gs = GridSearchCV(nn_pipeline, param_grid = params_nn, cv = 5, n_jobs = -1,\n",
        "scoring = \"accuracy\", verbose = 10)\n",
        "\n",
        "nn_gs.fit(X_train, y_train)\n",
        "y_nngs = nn_gs.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__alpha': 0.007428571428571429, 'model__hidden_layer_sizes': (400, 400)}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_gs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of the NN after tuning the number of neurons and the learning parameter alpha is: 0.9753\n"
          ]
        }
      ],
      "source": [
        "print(f'The accuracy of the NN after tuning the number of neurons and the learning parameter alpha is: {round(accuracy_score(y_test, y_nngs), 4)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. KNN  \n",
        "\n",
        "I tune the number of neighbors and the nubmer of clusters that the Feature Aggregation should create. It turns out that the initial guess of 196 was the best.\n",
        "However the algorithm took around 30 mins to fit, and it really slowed down my computer so I couldn't work on my Game Theory paper while this was fitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier()\n",
        "\n",
        "knn_pipeline = Pipeline(steps=[\n",
        "                              ('preprocess', col_trans),\n",
        "    ('feat_agg', cluster.FeatureAgglomeration(n_clusters=196)),\n",
        "                              ('model', knn_clf)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_params = {'model__n_neighbors':[i for i in range(3, 10)], 'feat_agg__n_clusters': [98, 196, 392]}\n",
        "\n",
        "knn_gs = GridSearchCV(knn_pipeline, param_grid= knn_params, n_jobs=-1, scoring='accuracy',\n",
        "cv = 5, verbose = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_gs.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'feat_agg__n_clusters': 196, 'model__n_neighbors': 5}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_gs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9424963924963925"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_preds = knn_gs.predict(X_test)\n",
        "accuracy_score(y_test, knn_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Output\n",
        "\n",
        "The best model was the NN with the tuned parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "nn_preds = nn_gs.predict(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_nn = pd.DataFrame({\"ImageId\":[i + 1 for i in range(len(nn_preds))], \"Label\": nn_preds})\n",
        "\n",
        "sub_nn.to_csv('submission_nn.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Charris_week10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
