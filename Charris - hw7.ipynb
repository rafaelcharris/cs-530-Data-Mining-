{"cells":[{"cell_type":"markdown","metadata":{"id":"27zGNShHVv1z"},"source":["# Random Forest\n","\n","The assignment is to add a Random Forest to your Week 6 homework.\n","\n","1)  Add an option to your handwritten Decision Tree so that it can consider only a random subset of features at each node (say, the sqrt(n_features)).\n","\n","2)  Add a random forest trainer that will create N bootstrapped datasets, and train a random Decision Tree for each.\n","\n","3)  Prediction should be based on a whichever outcome gets the most votes by the N trees.\n","\n","You can test that it's working on the iris dataset.\n","\n","Add an sklearn Random Forest to your model comparison for the Adult dataset like you did with the decision tree in the previous assignment.\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":154,"metadata":{"executionInfo":{"elapsed":160,"status":"ok","timestamp":1648189667723,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"csMbnJy-HhgG"},"outputs":[],"source":["import pandas as pd\n","import numpy as np \n","# Algorithm \n","from sklearn.ensemble import RandomForestClassifier\n","# Data Manipulation \n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import make_column_transformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_validate\n","from sklearn.preprocessing import StandardScaler\n","# Tuning\n","from sklearn.model_selection import GridSearchCV\n","\n","# Evaluation \n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import make_scorer\n","from sklearn.metrics import matthews_corrcoef\n","\n","df = pd.read_csv('iris.data')\n"]},{"cell_type":"markdown","metadata":{"id":"9eD_ytWdTHu8"},"source":["# Decision Tree"]},{"cell_type":"code","execution_count":155,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648189668004,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"2BzVNr_RVtIm"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","\n","df = pd.read_csv('PlayTennis.csv')"]},{"cell_type":"code","execution_count":156,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1648189668005,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"npLE5l9Kdhg3"},"outputs":[],"source":["def p(node, target):\n","  '''\n","  This function \n","  '''\n","  counts = Counter(node[target])\n","  return np.sum([(freq/len(node))**2 for key, freq in counts.items()])\n","\n","def gini_index(df, col, val, target):\n","  '''\n","  This function takes a col and splits it by the value an returns the gini index of this split\n","  '''\n","  if df[col].dtype == 'O' or df[col].dtype == 'bool':\n","    left = df[(df[col] == val)]\n","    right = df[(df[col] !=  val)]\n","  else:\n","    left = df[(df[col] \u003c= val)]\n","    right = df[(df[col] \u003e val)]\n","  p1 = p(left, target)\n","  p2 = p(right, target)\n","  # Get the predictions for each side. The prediction is just the category\n","  # (yes or no) that has the most observations \n","  try:\n","    left_pred = left[[target]].value_counts().sort_values(ascending = False).index[0][0]\n","    right_pred = right[[target]].value_counts().sort_values(ascending = False).index[0][0]\n","  except Exception:\n","    left_pred = ''\n","    right_pred = ''\n","  return len(left)/len(df)*(1- p1) + len(right)*(1 - p2)/len(df), (left_pred, right_pred)"]},{"cell_type":"code","execution_count":157,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1648189668005,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"l4C7vn08gckq"},"outputs":[],"source":["def get_best_gini(df, col, target):\n","  '''\n","  This functions loops through all the values of a column and\n","  return the column with the lowest gini index (the best one) for the split\n","  '''\n","  vals = df[col].unique()\n","  vals = sorted(vals)\n","  best_val = 0\n","  best_gini = 1\n","  best_preds = ''\n","  for val in vals:\n","    current_gini, current_preds  = gini_index(df, col, val, target)\n","    if current_gini \u003c best_gini:\n","      best_val = val\n","      best_gini = current_gini\n","      best_preds = current_preds\n","      \n","  return best_val, best_gini, best_preds\n"]},{"cell_type":"code","execution_count":158,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648189668005,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"b1H1tlP8r6fy"},"outputs":[],"source":["def get_best_column(df, target):\n","  '''\n","  This function picks the best column (the one with the lowest gini index) in\n","  the data frame and returns the column and the correct split\n","  '''\n","  best_col = ''\n","  best_gini = 10\n","  split_val = 0\n","  best_preds = ''\n","  X = list(df.columns)\n","  \n","  X.remove(target)\n","  for col in X:\n","    current_val, current_gini, current_preds = get_best_gini(df, col, target)\n","    if current_gini \u003c best_gini:\n","      best_col = col\n","      best_gini = current_gini\n","      split_val = current_val\n","      best_preds = current_preds\n","  return best_col, split_val, best_gini, best_preds\n"]},{"cell_type":"code","execution_count":159,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648189668005,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"a2-vATR0u3PN"},"outputs":[],"source":["def tree(node, max_depth, target):\n","  '''\n","  This function takes a node, and a max_depth of the tree.\n","  It gets the best split and procedes until the max_depth is achieved.\n","  '''\n","  current_df = node[0]\n","  #print(f'this are the columns in current_df = {current_df.columns}')\n","  col, split_by, gini, preds = get_best_column(current_df, target)\n","  #print(f'this is the col selected: {col}')\n","  if node[1] \u003e max_depth or node[3] == 0:\n","    full_tree[-1][3] = full_tree[-1][3] + '-END'\n","    return full_tree \n","\n","  #Split the tree by the best value and remove this column\n","\n","  if current_df[col].dtype == 'O' or current_df[col].dtype == 'bool':\n","    left_path = current_df[(current_df[col] == split_by)]\n","    right_path = current_df[(current_df[col] !=  split_by)]\n","  else:\n","    left_path = current_df[(current_df[col] \u003c= split_by)]\n","    right_path = current_df[(current_df[col] \u003e split_by)]\n","\n","  full_tree.append(node[1:])\n","  # Crete two new paths \n","  left_node = [left_path, node[1] + 1, (col, ' ==/\u003c= ' , split_by), \\\n","               gini, node[4] + 'L', preds[0]]\n","  right_node = [right_path, node[1] + 1, (col, '!=/\u003e ', split_by), \\\n","                gini, node[4] + 'R', preds[1]]\n","\n","  #Run the tree for these nodes again\n","  tree(left_node, max_depth, target)\n","  tree(right_node, max_depth, target)\n","  \n","  return full_tree"]},{"cell_type":"code","execution_count":160,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648189668005,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"dzMmlujNrxkt"},"outputs":[],"source":["def print_tree(x):\n","  '''\n","  Print tree in a nicer way (?)\n","  '''\n","  if len(x) == 0:\n","    return\n","  if x[0][0] \u003e 0:\n","    print(f'Node: {x[0][0]}', x[0][0]*'--','\u003e', x[0][1][0], x[0])\n","  new_tree = x[1:]\n","  print_tree(new_tree)\n","  return"]},{"cell_type":"markdown","metadata":{"id":"PwZAci1LUVM_"},"source":["## Predict Function\n"]},{"cell_type":"code","execution_count":161,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648189668005,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"7aNao8O6sSMb"},"outputs":[],"source":["path  = []\n","def walk_path(tree, row, path):\n","  '''\n","  This function returns the path that each row creates as it walks down the tree\n","  '''\n","  if len(tree) == 0:\n","    return []\n","\n","  row_dict = dict(row._asdict())\n","  try:\n","    split_feature = tree[1][1][0]\n","  except IndexError:\n","    return [] \n","  current_index = tree[0][0]\n","  if isinstance(row_dict[split_feature], float) or \\\n","  isinstance(row_dict[split_feature], int):\n","    if row_dict[split_feature] \u003c= tree[1][1][2]:\n","      \n","      path.append('L')\n","    else:\n","      path.append('R')\n","  else:\n","    if row_dict[split_feature] == tree[1][1][2]:\n","      path.append('L')\n","    else:\n","      path.append('R')\n","  new_tree = [p for p in tree if p[3].startswith(''.join(path))]\n","  walk_path(new_tree, row, path)\n","  return path\n","\n","\n","def predict(tree, X_cols):\n","  '''\n","  This function uses the walk_path function and applies it to the whole df \n","  '''\n","  preds = []\n","  for row in X_cols.itertuples():\n","    path = ''.join(walk_path(tree[1:], row, []))\n","    pred = [p[4] for p in tree if p[3] == path + \"-END-END\"]\n","    preds.append([row.Index, pred])\n","  return preds"]},{"cell_type":"code","execution_count":162,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648189668006,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"W8dBM5beyQRm"},"outputs":[],"source":["def accuracy(y_preds, y_real):\n","  '''\n","  This function checks the accuracy of the tree\n","  '''\n","  #print(f'y_preds: {y_preds}')\n","  y_p = [x[1] for x in y_preds]\n","  y_real = np.array(y_real.tolist())\n","  print(f'y_real: {y_real}\\ntype: {len(y_real), type(y_real)}'); print(f'y_p: {y_p}')\n","  return np.sum(y_p == y_real)/len(y_p)"]},{"cell_type":"markdown","metadata":{"id":"RlsGcPC3UtAa"},"source":["## Iris Data Set"]},{"cell_type":"code","execution_count":163,"metadata":{"executionInfo":{"elapsed":217,"status":"ok","timestamp":1648189668219,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"Dd2wnwaGUslq"},"outputs":[],"source":["iris = pd.read_csv('iris.data', names = ['sepal-length'\n","                                          ,'sepal-widt'\n","                                          ,'petal-leng'\n","                                          ,'petal-width',\n","                                         'class'],\n","                   skiprows = 1)\n","# This transformation is neccesary for the way I did things. For some reason\n","# itertuples() does not read properly names with '-' in them.\n","iris.columns = iris.columns.str.replace('-','_')"]},{"cell_type":"markdown","metadata":{"id":"teBUU39hH6dk"},"source":["# My Random Forest"]},{"cell_type":"code","execution_count":165,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648189668220,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"I6bHiA2HH8r8"},"outputs":[],"source":["full_tree = []\n","def RandomForest(df, target, X_test, n_bootstrap = 8, num_features = None):\n","  preds = []\n","  max_depth = 2\n","  for _ in range(n_bootstrap):\n","    # This is the bootstrap part\n","    df_bs = df.sample(axis = 0, frac = 0.3)\n","    import random\n","    import math \n","    # This is the random features part\n","    if isinstance(num_features, type(None)) or num_features == 0 :\n","      num_features = int(math.sqrt(len(df.columns)))\n","\n","    if num_features \u003e len(df.columns) - 1:\n","      # If the number of features given is larger than the actual, give the\n","      num_features = len(df.columns) - 1\n","\n","    # Select a random subset of features\n","    cols = list(df.columns)\n","    cols.remove(target)\n","    random_cols= random.sample(cols, k = num_features)\n","    sample_df = df.loc[:, random_cols + [target]]\n","    \n","    test_df = X_test.loc[:, random_cols]\n","    global full_tree \n","    full_tree = []\n","    node0 = [sample_df, 0, '', 1, '', '']\n","    t1 = tree(node0, max_depth, target)\n","    sub_preds = predict(t1, test_df)\n","\n","    preds.append(sub_preds)\n","  return preds\n"]},{"cell_type":"code","execution_count":166,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648189668221,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"N7rJi40FZScs"},"outputs":[],"source":["def get_highest(value):\n","  from collections import Counter\n","  dict_count = dict(Counter(value))\n","  try:\n","    return max(dict_count, key = dict_count.get)\n","  except ValueError:\n","    print('found error')\n","    return ''\n","\n","\n","def get_max_pred(preds):\n","  \n","  preds_dict = [*map(dict, preds)]\n","  final_dict = {}\n","  for index in preds_dict[0].keys():  \n","    final_dict[index] = []\n","    for x in range(len(preds_dict)):\n","      try:\n","        final_dict[index] += (preds_dict[x][index])      \n","      except KeyError:\n","        continue\n","  preds_dict = [[key, get_highest(value)] for key, value in final_dict.items()]\n","  return preds_dict \n"]},{"cell_type":"code","execution_count":167,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9568,"status":"ok","timestamp":1648189677783,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"},"user_tz":420},"id":"oe_MSnSMZWTs","outputId":"9405e7ae-c698-45f7-de72-f1ead4f93e42"},"outputs":[{"name":"stdout","output_type":"stream","text":["y_real: ['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n"," 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n"," 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n"," 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n"," 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n"," 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n"," 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n"," 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n"," 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n"," 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n"," 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n"," 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n"," 'Iris-virginica']\n","y_p: ['Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica']\n","The accuracy of this tree is: 0.52\n"]}],"source":["cols = list(iris.columns)\n","cols.remove('class')\n","X_iris = iris.loc[:,cols]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_iris, iris['class'], \n","                                                    test_size=0.33, random_state=42)\n","\n","iris_train = pd.concat([X_train, y_train], axis = 1)\n","\n","random_result = RandomForest(iris_train, 'class', X_test)\n","random_preds = get_max_pred(random_result)\n","\n","print(f\"The accuracy of this Random Forest is: {accuracy(random_preds, y_test)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"6-q_jZHRH3bA"},"source":["# SKlearn Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YbfVDIflHmoH"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n","  UserWarning,\n"]},{"data":{"text/plain":["0.8551071801486395"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('adult.data', names=['age',\n","              'workclass',\n","              'fnlwgt',\n","              'education',\n","              'education-num',\n","              'marital-status',\n","              'occupation',\n","              'relationship', 'race',\n","              'sex', \n","              'capital-gain',\n","              'capital-loss',\n","              'hours-per',\n","              'native-country', 'y'], index_col = False).drop(['education'], axis = 1)\n","\n","test = pd.read_csv('adul.test', names=['age',\n","              'workclass',\n","              'fnlwgt',\n","              'education',\n","              'education-num',\n","              'marital-status',\n","              'occupation',\n","              'relationship', 'race',\n","              'sex',\n","              'capital-gain',\n","              'capital-loss',\n","              'hours-per',\n","              'native-country', 'y'], index_col = False, skiprows = 1).\\\n","              drop(['education'], axis = 1)\n","\n","train['y'] = train['y'].apply(lambda x: x.replace('.', '').replace(' ', ''))\n","test['y'] = test['y'].apply(lambda x: x.replace('.', '').replace(' ', ''))\n","\n","X_train = train.drop(['y'], axis = 1)\n","y_train = train['y']\n","\n","X_test = test.drop(['y'], axis = 1)\n","y_test = test['y']\n","\n","col_trans = make_column_transformer((OneHotEncoder(handle_unknown = 'ignore', \n","                                                   drop = 'first'), \n","                                    list(X_train.select_dtypes(include = 'O').columns)),\n","                                    (StandardScaler(), \n","                                     list(X_train.select_dtypes(exclude = 'O').columns)),\n","                                    remainder = 'passthrough'\n","                                     )\n","\n","tree_pipe = Pipeline(steps = [\n","                         ('preprocess', col_trans), \n","                         ('model', RandomForestClassifier())\n","                         ])\n","\n","\n","parameters = {#'model__max_depth': [i + 1  for i in range(50)],\n","              'model__max_features': [i + 1 for i in range(len(X_train.columns))]}\n","\n","clf_pipe = GridSearchCV(tree_pipe, parameters, cv = 5,\n","                        scoring = make_scorer(matthews_corrcoef))\n","\n","clf_pipe.fit(X_train, y_train)\n","y_preds = clf_pipe.predict(X_test)\n","\n","accuracy_score(y_test, y_preds)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM4BQpoX20VTd02yIVMp9ut","collapsed_sections":[],"name":"Charris - hw7.ipynb","provenance":[{"file_id":"1mYMXiVXAMeluKjTcNc1j4-8A5wdcYUae","timestamp":1647994320717}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}