{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Charris - hw6.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN1/4FzCT0iwO1SrTahql69"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Decision Trees\n","\n","Your assignment is to write a CART decision tree from scratch, as we discussed in class.  Features should include:\n","\n","  - Having a maximum depth parameter.\n","\n","  - Ability to handle both categorical and continuous features\n","\n","  - Creating predictions for rows after fitting\n","\n","  - Ability to print the decision tree.  (see below for example)\n","\n","Apply your implementation to two datasets:\n","\n","1) The attached tennis dataset.  All features can be considered categorical.\n","\n","2) The iris dataset: https://archive.ics.uci.edu/ml/datasets/iris (Links to an external site.).  All features are numeric.\n","\n","Additionally, use the sklearn's implementation on the Adult dataset from Week 5's homework.  Be sure to tune at least 1 regularization hyperparameter (DecisionTreeClassifier for the available options).  Make a table comparing all the methods using Matthew's Correlation Coefficient.\n","\n"],"metadata":{"id":"27zGNShHVv1z"}},{"cell_type":"markdown","source":["# Decision Tree"],"metadata":{"id":"9eD_ytWdTHu8"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"2BzVNr_RVtIm","executionInfo":{"status":"ok","timestamp":1648150819615,"user_tz":420,"elapsed":415,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","\n","df = pd.read_csv('PlayTennis.csv')"]},{"cell_type":"code","source":["def p(node, target):\n","  '''\n","  This function \n","  '''\n","  counts = Counter(node[target])\n","  return np.sum([(freq/len(node))**2 for key, freq in counts.items()])\n","\n","def gini_index(df, col, val, target):\n","  '''\n","  This function takes a col and splits it by the value an returns the gini index of this split\n","  '''\n","  if df[col].dtype == 'O' or df[col].dtype == 'bool':\n","    left = df[(df[col] == val)]\n","    right = df[(df[col] !=  val)]\n","  else:\n","    left = df[(df[col] <= val)]\n","    right = df[(df[col] > val)]\n","  p1 = p(left, target)\n","  p2 = p(right, target)\n","  # Get the predictions for each side. The prediction is just the category\n","  # (yes or no) that has the most observations \n","  try:\n","    left_pred = left[[target]].value_counts().sort_values(ascending = False).index[0][0]\n","    right_pred = right[[target]].value_counts().sort_values(ascending = False).index[0][0]\n","  except Exception:\n","    left_pred = ''\n","    right_pred = ''\n","  return len(left)/len(df)*(1- p1) + len(right)*(1 - p2)/len(df), (left_pred, right_pred)"],"metadata":{"id":"npLE5l9Kdhg3","executionInfo":{"status":"ok","timestamp":1648150820780,"user_tz":420,"elapsed":699,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def get_best_gini(df, col, target):\n","  '''\n","  This functions loops through all the values of a column and\n","  return the column with the lowest gini index (the best one) for the split\n","  '''\n","  vals = df[col].unique()\n","  vals = sorted(vals)\n","  best_val = 0\n","  best_gini = 1\n","  best_preds = ''\n","  for val in vals:\n","    current_gini, current_preds  = gini_index(df, col, val, target)\n","    if current_gini < best_gini:\n","      best_val = val\n","      best_gini = current_gini\n","      best_preds = current_preds\n","      \n","  return best_val, best_gini, best_preds\n"],"metadata":{"id":"l4C7vn08gckq","executionInfo":{"status":"ok","timestamp":1648150820781,"user_tz":420,"elapsed":78,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def get_best_column(df, target):\n","  '''\n","  This function picks the best column (the one with the lowest gini index) in\n","  the data frame and returns the column and the correct split\n","  '''\n","  best_col = ''\n","  best_gini = 10\n","  split_val = 0\n","  best_preds = ''\n","  X = list(df.columns)\n","  \n","  X.remove(target)\n","  for col in X:\n","    current_val, current_gini, current_preds = get_best_gini(df, col, target)\n","    if current_gini < best_gini:\n","      best_col = col\n","      best_gini = current_gini\n","      split_val = current_val\n","      best_preds = current_preds\n","  return best_col, split_val, best_gini, best_preds\n"],"metadata":{"id":"b1H1tlP8r6fy","executionInfo":{"status":"ok","timestamp":1648150820781,"user_tz":420,"elapsed":76,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def tree(node, max_depth, target):\n","  '''\n","  This function takes a node, and a max_depth of the tree.\n","  It gets the best split and procedes until the max_depth is achieved.\n","  '''\n","  current_df = node[0]\n","  col, split_by, gini, preds = get_best_column(current_df, target)\n","  \n","  if node[1] > max_depth or node[3] == 0:\n","    full_tree[-1][3] = full_tree[-1][3] + '-END'\n","    return full_tree \n","\n","  #Split the tree by the best value and remove this column\n","\n","  if current_df[col].dtype == 'O' or current_df[col].dtype == 'bool':\n","    left_path = current_df[(current_df[col] == split_by)]\n","    right_path = current_df[(current_df[col] !=  split_by)]\n","  else:\n","    left_path = current_df[(current_df[col] <= split_by)]\n","    right_path = current_df[(current_df[col] > split_by)]\n","\n","  full_tree.append(node[1:])\n","\n","  # Crete two new paths \n","  left_node = [left_path, node[1] + 1, (col, ' ==/<= ' , split_by), gini, node[4] + 'L', preds[0]]\n","  right_node = [right_path, node[1] + 1, (col, '!=/> ', split_by), gini, node[4] + 'R', preds[1]]\n","\n","  #Run the tree for these nodes again\n","  tree(left_node, max_depth, target)\n","  tree(right_node, max_depth, target)\n","  \n","  return full_tree"],"metadata":{"id":"a2-vATR0u3PN","executionInfo":{"status":"ok","timestamp":1648150820781,"user_tz":420,"elapsed":75,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def print_tree(x):\n","  '''\n","  Print tree in a nicer way (?)\n","  '''\n","  if len(x) == 0:\n","    return\n","  if x[0][0] > 0:\n","    print(f'Node: {x[0][0]}', x[0][0]*'--','>', x[0][1][0], x[0])\n","  new_tree = x[1:]\n","  print_tree(new_tree)\n","  return"],"metadata":{"id":"dzMmlujNrxkt","executionInfo":{"status":"ok","timestamp":1648150820781,"user_tz":420,"elapsed":72,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Predict Function\n"],"metadata":{"id":"PwZAci1LUVM_"}},{"cell_type":"code","source":["path  = []\n","def walk_path(tree, row, path):\n","  '''\n","  This function returns the path that each row creates as it walks down the tree\n","  '''\n","  if len(tree) == 0:\n","    return []\n","\n","  row_dict = dict(row._asdict())\n","  try:\n","    split_feature = tree[1][1][0]\n","  except IndexError:\n","    return [] \n","  current_index = tree[0][0]\n","  if isinstance(row_dict[split_feature], float) or isinstance(row_dict[split_feature], int):\n","    if row_dict[split_feature] <= tree[1][1][2]:\n","      \n","      path.append('L')\n","    else:\n","      path.append('R')\n","  else:\n","    if row_dict[split_feature] == tree[1][1][2]:\n","      path.append('L')\n","    else:\n","      path.append('R')\n","  new_tree = [p for p in tree if p[3].startswith(''.join(path))]\n","  walk_path(new_tree, row, path)\n","  return path\n","\n","\n","def predict(tree, X_train):\n","  '''\n","  This function uses the walk_path function and applies it to the whole df \n","  '''\n","  preds = []\n","  for row in X_train.itertuples():\n","    path = ''.join(walk_path(tree[1:], row, []))\n","    pred = [p[4] for p in tree if p[3] == path + \"-END-END\"]\n","\n","    preds.append([row.Index, pred])\n","  return preds\n"],"metadata":{"id":"7aNao8O6sSMb","executionInfo":{"status":"ok","timestamp":1648150820782,"user_tz":420,"elapsed":70,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def accuracy(y_preds, y_real):\n","  '''\n","  This function checks the accuracy of the tree\n","  '''\n","  y_p = [x[1][0] for x in y_preds]\n","  y_real = np.array(y_real.tolist())\n","  return np.sum(y_p == y_real)/len(y_p)"],"metadata":{"id":"W8dBM5beyQRm","executionInfo":{"status":"ok","timestamp":1648150820782,"user_tz":420,"elapsed":69,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Play Tennis data\n","\n","To apply my function to a new data set I need a node 0 to initialize the tree. Each node will have the split variable and it's threshold value, the gini index of the previous split, the path, and the prediction of the y variable if you take the 'y'."],"metadata":{"id":"D4S-mvI2Unu8"}},{"cell_type":"code","source":["# The first node takes the current data, the depth, and the split history\n","node0 = [df, 0, '', 1, '', '']\n","max_depth = 5\n","full_tree = []\n","tenis_tree = tree(node0, max_depth, 'play')\n","print_tree(tenis_tree)"],"metadata":{"id":"fnZdZeg1G5ns","executionInfo":{"status":"ok","timestamp":1648150832143,"user_tz":420,"elapsed":848,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"31d0d8d2-8354-4b96-d60a-3948264262c5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Node: 1 -- > outlook [1, ('outlook', ' ==/<= ', 'overcast'), 0.35714285714285715, 'L-END-END', 'yes']\n","Node: 1 -- > outlook [1, ('outlook', '!=/> ', 'overcast'), 0.35714285714285715, 'R', 'no']\n","Node: 2 ---- > humidity [2, ('humidity', ' ==/<= ', 'high'), 0.31999999999999984, 'RL', 'no']\n","Node: 3 ------ > outlook [3, ('outlook', ' ==/<= ', 'rainy'), 0.2, 'RLL-END-END', 'no']\n","Node: 3 ------ > outlook [3, ('outlook', '!=/> ', 'rainy'), 0.2, 'RLR-END-END', 'no']\n","Node: 2 ---- > humidity [2, ('humidity', '!=/> ', 'high'), 0.31999999999999984, 'RR', 'yes']\n","Node: 3 ------ > windy [3, ('windy', ' ==/<= ', False), 0.2, 'RRL-END-END', 'yes']\n","Node: 3 ------ > windy [3, ('windy', '!=/> ', False), 0.2, 'RRR-END-END', 'no']\n"]}]},{"cell_type":"markdown","source":["## Iris Data Set"],"metadata":{"id":"RlsGcPC3UtAa"}},{"cell_type":"code","source":["iris = pd.read_csv('iris.data', names = ['sepal-length'\n","                                          ,'sepal-widt'\n","                                          ,'petal-leng'\n","                                          ,'petal-width',\n","                                         'class'],\n","                   skiprows = 1)\n","iris.head()\n","# This transformation is neccesary for the way I did things. For some reason\n","# itertuples() does not read properly names with '-' in them.\n","iris.columns = iris.columns.str.replace('-','_')"],"metadata":{"id":"Dd2wnwaGUslq","executionInfo":{"status":"ok","timestamp":1648150836161,"user_tz":420,"elapsed":426,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["node0 = [iris, 0, '', 1, '', '']\n","full_tree = []\n","iris_tree = tree(node0, max_depth = 8, target = 'class')\n","print_tree(iris_tree)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsSdPiFnLjwy","executionInfo":{"status":"ok","timestamp":1648150842593,"user_tz":420,"elapsed":3568,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}},"outputId":"79481cf4-4e2a-4cc9-9ef4-7090f39abf9d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Node: 1 -- > petal_leng [1, ('petal_leng', ' ==/<= ', 1.9), 0.33557046979865773, 'L-END-END', 'Iris-setosa']\n","Node: 1 -- > petal_leng [1, ('petal_leng', '!=/> ', 1.9), 0.33557046979865773, 'R', 'Iris-versicolor']\n","Node: 2 ---- > petal_width [2, ('petal_width', ' ==/<= ', 1.7), 0.11030595813204513, 'RL', 'Iris-versicolor']\n","Node: 3 ------ > petal_leng [3, ('petal_leng', ' ==/<= ', 4.9), 0.0856481481481482, 'RLL-END-END', 'Iris-versicolor']\n","Node: 3 ------ > petal_leng [3, ('petal_leng', '!=/> ', 4.9), 0.0856481481481482, 'RLR', 'Iris-virginica']\n","Node: 4 -------- > petal_width [4, ('petal_width', ' ==/<= ', 1.5), 0.2222222222222222, 'RLRL-END-END', 'Iris-virginica']\n","Node: 4 -------- > petal_width [4, ('petal_width', '!=/> ', 1.5), 0.2222222222222222, 'RLRR-END-END', 'Iris-versicolor']\n","Node: 2 ---- > petal_width [2, ('petal_width', '!=/> ', 1.7), 0.11030595813204513, 'RR', 'Iris-virginica']\n","Node: 3 ------ > petal_leng [3, ('petal_leng', ' ==/<= ', 4.8), 0.02898550724637681, 'RRL-END-END', 'Iris-virginica']\n","Node: 3 ------ > petal_leng [3, ('petal_leng', '!=/> ', 4.8), 0.02898550724637681, 'RRR-END-END', 'Iris-virginica']\n"]}]},{"cell_type":"markdown","source":["## Predictions"],"metadata":{"id":"3paS03mB2V8D"}},{"cell_type":"markdown","source":["### On the tenis data"],"metadata":{"id":"MJroKZEI2dqk"}},{"cell_type":"code","source":["cols =list(df.columns)\n","cols.remove('play') \n","X_train = df.loc[:, cols]\n","\n","for x in range(len(X_train)):\n","  print(df['play'].iloc[x], predict(tenis_tree, X_train)[x][1])\n","\n","print(f\"The accuracy of this tree is: {accuracy(predict(tenis_tree, X_train), df['play'])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ohLZvZKS2bdM","executionInfo":{"status":"ok","timestamp":1647907351574,"user_tz":420,"elapsed":19,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}},"outputId":"c89e6932-1231-494c-8d4e-7fd4569efd0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["no ['no']\n","no ['no']\n","yes ['yes']\n","yes ['no']\n","yes ['yes']\n","no ['no']\n","yes ['yes']\n","no ['no']\n","yes ['yes']\n","yes ['yes']\n","yes ['no']\n","yes ['yes']\n","yes ['yes']\n","no ['no']\n","The accuracy of this tree is: 0.8571428571428571\n"]}]},{"cell_type":"markdown","source":["### On the iris data"],"metadata":{"id":"R9KWGJjZ2fge"}},{"cell_type":"code","source":["iris = pd.read_csv('iris.data', names = ['sepal-length'\n","                                          ,'sepal-widt'\n","                                          ,'petal-leng'\n","                                          ,'petal-width',\n","                                         'class'],\n","                   skiprows = 1)\n","\n","# This transformation is neccesary for the way I did things. For some reason\n","# itertuples() does not read properly names with '-' in them.\n","iris.columns = iris.columns.str.replace('-','_')\n","\n","cols = list(iris.columns)\n","cols.remove('class')\n","X_iris = iris.loc[:,cols]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_iris, iris['class'], test_size=0.33, random_state=42)\n","\n","iris_train = pd.concat([X_train, y_train], axis = 1)\n","#iris_test = pd.concat([X_test, y_test], axis = 1)\n","\n","node0 = [iris_train, 0, '', 1, '', '']\n","full_tree = []\n","iris_tree = tree(node0, max_depth = 8, target = 'class')\n","print_tree(iris_tree)\n","\n","\n","print(f\"The accuracy of this tree is: {accuracy(predict(iris_tree, X_test), y_test)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvT8BHSF2dN0","executionInfo":{"status":"ok","timestamp":1648150893869,"user_tz":420,"elapsed":2229,"user":{"displayName":"Rafael Charris Dominguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00310138805331914177"}},"outputId":"a3f69bb8-60cc-4dfe-8722-3d3b90f91883"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Node: 1 -- > petal_leng [1, ('petal_leng', ' ==/<= ', 4.7), 0.3415945165945166, 'L-END-END', 'Iris-versicolor']\n","Node: 1 -- > petal_leng [1, ('petal_leng', '!=/> ', 4.7), 0.3415945165945166, 'R', 'Iris-virginica']\n","Node: 2 ---- > petal_width [2, ('petal_width', ' ==/<= ', 1.5), 0.03809523809523809, 'RL-END-END', 'Iris-virginica']\n","Node: 2 ---- > petal_width [2, ('petal_width', '!=/> ', 1.5), 0.03809523809523809, 'RR-END-END', 'Iris-virginica']\n","The accuracy of this tree is: 0.5\n"]}]},{"cell_type":"markdown","source":["My tree is not that good in predicting when using 70 % of the data as training data. When I use the whole data frame it 'succesfully' over-fits the data and i get around 95% accuracy."],"metadata":{"id":"ql0VpjQvNAmI"}},{"cell_type":"markdown","source":["# Sklearn Tree"],"metadata":{"id":"VZBQJY9DHLIh"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import make_column_transformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_validate\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import make_scorer\n","\n","train = pd.read_csv('adult.data', names=['age',\n","              'workclass',\n","              'fnlwgt',\n","              'education',\n","              'education-num',\n","              'marital-status',\n","              'occupation',\n","              'relationship', 'race',\n","              'sex', \n","              'capital-gain',\n","              'capital-loss',\n","              'hours-per',\n","              'native-country', 'y'], index_col = False).drop(['education'], axis = 1)\n","\n","test = pd.read_csv('adult.test', names=['age',\n","              'workclass',\n","              'fnlwgt',\n","              'education',\n","              'education-num',\n","              'marital-status',\n","              'occupation',\n","              'relationship', 'race',\n","              'sex',\n","              'capital-gain',\n","              'capital-loss',\n","              'hours-per',\n","              'native-country', 'y'], index_col = False, skiprows = 1).\\\n","              drop(['education'], axis = 1)\n","\n","train['y'] = train['y'].apply(lambda x: x.replace('.', '').replace(' ', ''))\n","test['y'] = test['y'].apply(lambda x: x.replace('.', '').replace(' ', ''))\n","\n","X_train = train.drop(['y'], axis = 1)\n","y_train = train['y']\n","\n","X_test = test.drop(['y'], axis = 1)\n","y_test = test['y']\n","\n","col_trans = make_column_transformer((OneHotEncoder(handle_unknown = 'ignore', \n","                                                   drop = 'first'), \n","                                    list(X_train.select_dtypes(include = 'O').columns)),\n","                                    (StandardScaler(), \n","                                     list(X_train.select_dtypes(exclude = 'O').columns)),\n","                                    remainder = 'passthrough'\n","                                     )\n","\n","tree_pipe = Pipeline(steps = [\n","                         ('preprocess', col_trans), \n","                         ('model', DecisionTreeClassifier())\n","                         ])\n","\n","\n","parameters = {'model__max_depth': [i + 1  for i in range(50)]}\n","\n","clf_pipe = GridSearchCV(tree_pipe, parameters, cv = 5,\n","                        scoring = make_scorer(matthews_corrcoef))\n","\n","clf_pipe.fit(X_train, y_train)\n","y_preds = clf_pipe.predict(X_test)\n","\n","accuracy_score(y_test, y_preds)"],"metadata":{"id":"kMnAmRZx3sOy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["methods_table = pd.DataFrame({\"Max Depth\": [i + 1 for i in range(15)], \n","              \"Matthews Correlation Coefficient\": clf_pipe.cv_results_['mean_test_score'][:15]})\n","\n","\n","def color_best(val):\n","  if val == methods_table[['Matthews Correlation Coefficient']].max()[0]:\n","    color = 'green'\n","  else:\n","    color = 'white'\n","  return 'color: %s' % color\n","\n","methods_table.style.applymap(color_best)"],"metadata":{"id":"zTrFqoT4w3ai"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The grid search found that the optimal tree depth is 10, because it hs the highest matthews correlation coefficient : 0.58.\n","\n"],"metadata":{"id":"ZYwt2zG581br"}}]}
